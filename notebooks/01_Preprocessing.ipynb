{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d8ff6cbb",
            "metadata": {},
            "source": [
                "# Clasificador Multietiqueta de Eventos Sísmicos\n",
                "Este *notebook* procesa una **base de acelerogramas** y genera un conjunto de datos limpio y uniformemente muestreado para modelos de *Machine Learning*.  \n",
                "Los bloques de código originales **no se alteran** en su lógica; solo se añaden comentarios detallados y celdas *Markdown* para guiar la lectura."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b59dbfef",
            "metadata": {},
            "source": [
                "## Bloque 1 – Importación de librerías"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "id": "7b86b91b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 1: Importación de librerías\n",
                "# ----------------------------------------------------------------------------------\n",
                "import os\n",
                "import re\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from collections import defaultdict, Counter\n",
                "from itertools import groupby, zip_longest\n",
                "import pickle"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "737b0767",
            "metadata": {},
            "source": [
                "## Bloque 2 – Extracción de datos brutos"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "id": "86dbb9e4",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Extracted data/raw/Base-sismos-2024.zip to data/raw/Base-sismos-2024\n"
                    ]
                }
            ],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 2: Preparación del directorio y descompresión de archivos\n",
                "# ----------------------------------------------------------------------------------\n",
                "# Si el directorio no es Seismic-Multilabel-Event-Classifier, se sale un directorio\n",
                "if not os.path.basename(os.getcwd()) == 'Seismic-Multilabel-Event-Classifier':\n",
                "    os.chdir('..')\n",
                "    print(f\"Changed directory to {os.getcwd()}\")\n",
                "import zipfile\n",
                "zip_path = 'data/raw/Base-sismos-2024.zip'\n",
                "extract_to = 'data/raw/Base-sismos-2024'\n",
                "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
                "    zip_ref.extractall(extract_to)\n",
                "print(f\"Extracted {zip_path} to {extract_to}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c8ca76bd",
            "metadata": {},
            "source": [
                "## Bloque 3 – Función `processNGAfile`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "195df91c",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 3: Definición de la función `processNGAfile`\n",
                "# ----------------------------------------------------------------------------------\n",
                "\"\"\"\n",
                "@author: Daniel Hutabarat - UC Berkeley, 2017\n",
                "\"\"\"\n",
                "\n",
                "def processNGAfile(filepath, scalefactor=None):\n",
                "    '''\n",
                "    Esta función procesa un historial de aceleración de un archivo de datos NGA (.AT2)\n",
                "    a un vector de una sola columna y devuelve el número total de puntos de datos y\n",
                "    el intervalo de tiempo de la grabación.\n",
                "\n",
                "    Parámetros:\n",
                "    ------------\n",
                "    filepath : string\n",
                "        Ruta y nombre del archivo.\n",
                "    scalefactor : float (opcional)\n",
                "        Factor de escala que se aplica a cada componente del arreglo de aceleración.\n",
                "\n",
                "    Salida:\n",
                "    ------------\n",
                "    npts: número total de puntos registrados (datos de aceleración)\n",
                "    dt: intervalo de tiempo entre los puntos registrados\n",
                "    time: array (n x 1) - arreglo de tiempos, misma longitud que npts\n",
                "    inp_acc: array (n x 1) - arreglo de aceleraciones, misma longitud que time,\n",
                "             la unidad usualmente es en g (gravedad) a menos que se indique lo contrario.\n",
                "\n",
                "    Ejemplo (graficar tiempo vs aceleración):\n",
                "    filepath = os.path.join(os.getcwd(),'motion_1')\n",
                "    npts, dt, time, inp_acc = processNGAfile(filepath)\n",
                "    plt.plot(time, inp_acc)\n",
                "    '''\n",
                "    try:\n",
                "        if not scalefactor:\n",
                "            scalefactor = 1.0  # Si no se proporciona, usa un factor de escala por defecto de 1.0\n",
                "\n",
                "        with open(filepath, 'r') as f:\n",
                "            content = f.readlines()  # Lee todas las líneas del archivo\n",
                "\n",
                "        counter = 0\n",
                "        desc, row4Val, acc_data = \"\", \"\", []\n",
                "\n",
                "        for x in content:\n",
                "            if counter == 3:\n",
                "                # En la línea 4 se suele encontrar la información NPTS y DT\n",
                "                row4Val = x\n",
                "                if row4Val[0][0] == 'N':\n",
                "                    npts_match = re.search(r'NPTS\\s*=\\s*([0-9.]+)', row4Val)\n",
                "                if npts_match:\n",
                "                    npts = float(npts_match.group(1))  # Número total de puntos\n",
                "                else:\n",
                "                    raise ValueError(\"No se encontró un valor para NPTS.\")\n",
                "                dt_match = re.search(r'DT\\s*=\\s*([0-9.]+)', row4Val)\n",
                "                if dt_match:\n",
                "                    dt = float(dt_match.group(1))  # Intervalo de tiempo entre puntos\n",
                "                else:\n",
                "                    raise ValueError(\"No se encontró un valor para DT.\")\n",
                "            elif counter == 4:\n",
                "                # En la línea 5 puede comenzar la data, si no hay encabezados adicionales\n",
                "                row4Val = x\n",
                "                #print(row4Val)\n",
                "                # Si comienza directamente con números o signos, asume que son datos de aceleración\n",
                "                if row4Val[0][0] == '.' or row4Val[0][0] == '-' or row4Val[0][0].isdigit() or row4Val[0][0] == ' ':\n",
                "                    print(\"Datos de aceleración encontrados en la línea 5.\")\n",
                "                    data = str(x).split()\n",
                "                    for value in data:\n",
                "                        a = float(value) * scalefactor\n",
                "                        acc_data.append(a)\n",
                "\n",
                "                    # Convierte lista a array de numpy\n",
                "                    inp_acc = np.asarray(acc_data)\n",
                "\n",
                "                    # Crea el vector de tiempo con base en el número de puntos y el dt\n",
                "                    time = []\n",
                "                    for i in range(len(acc_data)):\n",
                "                        t = i * dt\n",
                "                        time.append(t)\n",
                "\n",
                "            elif counter > 4:\n",
                "                # Las siguientes líneas después de la 5ta contienen más datos de aceleración\n",
                "                data = str(x).split()\n",
                "                for value in data:\n",
                "                    a = float(value) * scalefactor\n",
                "                    acc_data.append(a)\n",
                "\n",
                "                inp_acc = np.asarray(acc_data)\n",
                "\n",
                "                # Genera de nuevo el vector de tiempo basado en la longitud actual\n",
                "                time = []\n",
                "                for i in range(len(acc_data)):\n",
                "                    t = i * dt\n",
                "                    time.append(t)\n",
                "\n",
                "            counter = counter + 1\n",
                "\n",
                "        # Devuelve los resultados procesados\n",
                "        return npts, dt, time, inp_acc\n",
                "\n",
                "    except IOError:\n",
                "        print(\"¡processMotion FALLÓ!: El archivo no se encuentra en el directorio.\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39113fa1",
            "metadata": {},
            "source": [
                "## Bloque 4 – Función `procesarDatos`"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c4c8cbc0",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 4: Definición de la función `procesarDatos`\n",
                "# ----------------------------------------------------------------------------------\n",
                "def procesarDatos(ruta_archivo):\n",
                "    # Lista general que almacenará los registros de todas las carpetas procesadas\n",
                "    registro = []\n",
                "\n",
                "    # Subcarpetas específicas que contienen los archivos que queremos procesar\n",
                "    subcarpetas_especificas = [\n",
                "        \"Componente Horizontal 1\",\n",
                "        \"Componente Horizontal 2\",\n",
                "        \"Componente Vertical\",\n",
                "    ]\n",
                "\n",
                "    # Recorre recursivamente todas las carpetas, subcarpetas y archivos desde la ruta base\n",
                "    for carpeta_raiz, subcarpetas, archivos in os.walk(ruta_archivo):\n",
                "        registro1 = []  # Acumula los registros de una carpeta raíz específica\n",
                "\n",
                "        # Revisa cada subcarpeta para verificar si es una de las que nos interesa\n",
                "        for subcarpeta in subcarpetas:\n",
                "            if subcarpeta in subcarpetas_especificas:\n",
                "                ruta_subcarpeta = os.path.join(carpeta_raiz, subcarpeta)\n",
                "                print(f\"Procesando subcarpeta: {ruta_subcarpeta}\")\n",
                "\n",
                "                registros = []  # Lista temporal de registros para esta subcarpeta\n",
                "\n",
                "                # Procesa todos los archivos en la subcarpeta\n",
                "                for archivo in os.listdir(ruta_subcarpeta):\n",
                "                    # Asegura que sea un archivo (y no una carpeta)\n",
                "                    if os.path.isfile(os.path.join(ruta_subcarpeta, archivo)):\n",
                "                        ruta_archivo = os.path.join(ruta_subcarpeta, archivo)\n",
                "                        #print(f\"Procesando archivo: {ruta_archivo}\")\n",
                "\n",
                "                        # Usa la función externa processNGAfile para extraer datos del archivo\n",
                "                        ntps, dt, time, inp_acc = processNGAfile(ruta_archivo)\n",
                "\n",
                "                        # Extrae metadatos a partir de la estructura del path del archivo\n",
                "                        rutaS = ruta_archivo.split('/')\n",
                "                        falla = rutaS[rutaS.index('Base-sismos-2024') + 1]  # Nombre de la falla\n",
                "                        mag = re.search(r'(\\d+-\\d+)', rutaS[rutaS.index('Base-sismos-2024') + 2]).group(0)  # Rango de magnitud\n",
                "                        vs = rutaS[rutaS.index('Base-sismos-2024') + 3].split(\"Vs30.\")[1].strip()  # Valor de Vs30\n",
                "                        tipo = rutaS[rutaS.index('Base-sismos-2024') + 4]  # Tipo de aceleración (H1, H2, V)\n",
                "                        # Crea un diccionario con todos los datos y lo añade a la lista\n",
                "                        registros.append({\n",
                "                            'Archivo': archivo,\n",
                "                            'NPTS': ntps,\n",
                "                            'DT': dt,\n",
                "                            'Falla': falla,\n",
                "                            'Mag': mag,\n",
                "                            'Vs': vs,\n",
                "                            'Time': time,\n",
                "                            'Acc': inp_acc,\n",
                "                            'Tipo': tipo\n",
                "                        })\n",
                "\n",
                "                # Agrega todos los registros procesados de esta subcarpeta al conjunto de esta carpeta raíz\n",
                "                registro1.extend(registros)\n",
                "\n",
                "        # Si se procesaron registros en esta carpeta raíz, se agregan al registro global\n",
                "        if len(registro1) != 0:\n",
                "            print(\"Registro de una carpeta completado\")\n",
                "            registro.append(registro1)\n",
                "\n",
                "    # Devuelve todos los registros organizados por carpeta raíz\n",
                "    return registro\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ae11bc1a",
            "metadata": {},
            "source": [
                "## Bloque 5 – Procesamiento inicial"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3cd55688",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 5: Ejecución de `procesarDatos`\n",
                "# ----------------------------------------------------------------------------------\n",
                "ruta_base = 'data/raw/Base-sismos-2024'\n",
                "datos_procesados = procesarDatos(ruta_base)\n",
                "print(\"Datos procesados.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4c1844ae",
            "metadata": {},
            "source": [
                "## Bloque 6 – Serialización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "79e6a35d",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 6: Guardar resultados con `pickle`\n",
                "# ----------------------------------------------------------------------------------\n",
                "os.makedirs('data/interim', exist_ok=True)\n",
                "with open('data/interim/datosML.pkl', 'wb') as f:\n",
                "    pickle.dump(datos_procesados, f)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac190872",
            "metadata": {},
            "source": [
                "## Bloque 7 – Deserialización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "ceecc85d",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Datos cargados.\n"
                    ]
                }
            ],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 7: Cargar datos serializados\n",
                "# ----------------------------------------------------------------------------------\n",
                "with open('data/interim/datosML.pkl', 'rb') as f:\n",
                "    registros_por_carpeta = pickle.load(f)\n",
                "print(\"Datos cargados.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8a0f9f61",
            "metadata": {},
            "source": [
                "## Bloque 8 – Agrupación y limpieza"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "24bf570b",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Total registros agrupados: 1696\n"
                    ]
                }
            ],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 8: Agrupar componentes, validar y limpiar duplicados\n",
                "# ----------------------------------------------------------------------------------\n",
                "from collections import defaultdict\n",
                "resultados = []\n",
                "for archivos in registros_por_carpeta:\n",
                "    grupos = defaultdict(list)\n",
                "    for archivo in archivos:\n",
                "        nombre_base = archivo['Archivo'].rsplit('_', 1)[0]\n",
                "        grupos[nombre_base].append(archivo)\n",
                "\n",
                "    for nombre_base, archivos_grupo in grupos.items():\n",
                "        npts = archivos_grupo[0]['NPTS']\n",
                "        dt = archivos_grupo[0]['DT']\n",
                "        if len(archivos_grupo) != 3:\n",
                "            continue\n",
                "        # Ajuste de NPTS discrepantes\n",
                "        if any(archivo['NPTS'] != npts for archivo in archivos_grupo):\n",
                "            minNpts = int(min(a['NPTS'] for a in archivos_grupo))\n",
                "            for archivo in archivos_grupo:\n",
                "                archivo['NPTS'] = minNpts\n",
                "                archivo['Time'] = archivo['Time'][:minNpts]\n",
                "                archivo['Acc'] = archivo['Acc'][:minNpts]\n",
                "\n",
                "        agrupado = {\n",
                "            'Archivo': nombre_base,\n",
                "            'NPTS': npts,\n",
                "            'DT': dt,\n",
                "            'Falla': archivos_grupo[0]['Falla'],\n",
                "            'Mag': archivos_grupo[0]['Mag'],\n",
                "            'Vs': archivos_grupo[0]['Vs'],\n",
                "            'Time': archivos_grupo[0]['Time'],\n",
                "            'AccV': None,\n",
                "            'AccH2': None,\n",
                "            'AccH1': None\n",
                "        }\n",
                "        for archivo in archivos_grupo:\n",
                "            if archivo['Tipo'] == 'Componente Horizontal 1':\n",
                "                agrupado['AccH1'] = archivo['Acc']\n",
                "            elif archivo['Tipo'] == 'Componente Horizontal 2':\n",
                "                agrupado['AccH2'] = archivo['Acc']\n",
                "            elif archivo['Tipo'] == 'Componente Vertical':\n",
                "                agrupado['AccV'] = archivo['Acc']\n",
                "        resultados.append(agrupado)\n",
                "print(f\"Total registros agrupados: {len(resultados)}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c5354d4d",
            "metadata": {},
            "source": [
                "## Bloque 9 – Normalización temporal"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "30c02a40",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 9: Función `normalizarSeries`\n",
                "# ----------------------------------------------------------------------------------\n",
                "from scipy.interpolate import interp1d\n",
                "def normalizarSeries(grupos):\n",
                "    dt = 0.01\n",
                "    for g in grupos:\n",
                "        t_orig = g['Time']\n",
                "        t_new = np.arange(0, t_orig[-1] + dt, dt)\n",
                "        g['AccH1'] = interp1d(t_orig, g['AccH1'], kind='linear', bounds_error=False, fill_value='extrapolate')(t_new)\n",
                "        g['AccH2'] = interp1d(t_orig, g['AccH2'], kind='linear', bounds_error=False, fill_value='extrapolate')(t_new)\n",
                "        g['AccV']  = interp1d(t_orig, g['AccV'],  kind='linear', bounds_error=False, fill_value='extrapolate')(t_new)\n",
                "        g['Time'] = t_new\n",
                "    return grupos"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4df3587a",
            "metadata": {},
            "source": [
                "## Bloque 10 – Aplicar normalización"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "1e8e201c",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Normalización completada.\n"
                    ]
                }
            ],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 10: Aplicar `normalizarSeries`\n",
                "# ----------------------------------------------------------------------------------\n",
                "grupos_normalizados = normalizarSeries(resultados)\n",
                "print(\"Normalización completada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "449eab92",
            "metadata": {},
            "source": [
                "## Bloque 11 – DataFrame"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "99751d84",
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Archivo</th>\n",
                            "      <th>NPTS</th>\n",
                            "      <th>Falla</th>\n",
                            "      <th>Mag</th>\n",
                            "      <th>Vs</th>\n",
                            "      <th>Time</th>\n",
                            "      <th>AccV</th>\n",
                            "      <th>AccH2</th>\n",
                            "      <th>AccH1</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>RSN8478_PARK2004</td>\n",
                            "      <td>32169.0</td>\n",
                            "      <td>1 Stiker Slip (SS)</td>\n",
                            "      <td>4-6</td>\n",
                            "      <td>600-</td>\n",
                            "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
                            "      <td>[3.3443977e-08, 3.3695554e-08, 3.3943394e-08, ...</td>\n",
                            "      <td>[-5.5774385e-08, -5.6530193e-08, -5.7289814e-0...</td>\n",
                            "      <td>[-1.931981e-08, -1.9326151e-08, -1.9334876e-08...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>RSN8700_40204628</td>\n",
                            "      <td>20001.0</td>\n",
                            "      <td>1 Stiker Slip (SS)</td>\n",
                            "      <td>4-6</td>\n",
                            "      <td>600-</td>\n",
                            "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
                            "      <td>[8.5424888e-09, 8.8524636e-09, 9.1842936e-09, ...</td>\n",
                            "      <td>[-2.2300064e-09, -2.3446809e-09, -2.4440089e-0...</td>\n",
                            "      <td>[8.4741547e-10, 1.2447632e-09, 1.6283558e-09, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>RSN8459_PARK2004</td>\n",
                            "      <td>32380.0</td>\n",
                            "      <td>1 Stiker Slip (SS)</td>\n",
                            "      <td>4-6</td>\n",
                            "      <td>600-</td>\n",
                            "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
                            "      <td>[5.855578e-08, 5.9356899e-08, 6.0156329e-08, 6...</td>\n",
                            "      <td>[2.7169869e-08, 2.7004326e-08, 2.6835684e-08, ...</td>\n",
                            "      <td>[1.5000493e-08, 1.4939016e-08, 1.4878223e-08, ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>RSN2148_BEARCTY</td>\n",
                            "      <td>8200.0</td>\n",
                            "      <td>1 Stiker Slip (SS)</td>\n",
                            "      <td>4-6</td>\n",
                            "      <td>600-</td>\n",
                            "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
                            "      <td>[-2.276836e-05, -2.118971e-05, -2.810751e-05, ...</td>\n",
                            "      <td>[7.43878e-06, 5.521958e-06, -2.429367e-06, -6....</td>\n",
                            "      <td>[1.001939e-05, 9.63514e-06, 1.253978e-05, 1.00...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>RSN8426_BEARCTY</td>\n",
                            "      <td>14465.0</td>\n",
                            "      <td>1 Stiker Slip (SS)</td>\n",
                            "      <td>4-6</td>\n",
                            "      <td>600-</td>\n",
                            "      <td>[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...</td>\n",
                            "      <td>[3.079444e-09, 3.07869528e-09, 3.07794452e-09,...</td>\n",
                            "      <td>[4.3128452e-10, 4.27025392e-10, 4.22775078e-10...</td>\n",
                            "      <td>[2.9098055e-09, 2.89089174e-09, 2.87200576e-09...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "            Archivo     NPTS               Falla  Mag    Vs  \\\n",
                            "0  RSN8478_PARK2004  32169.0  1 Stiker Slip (SS)  4-6  600-   \n",
                            "1  RSN8700_40204628  20001.0  1 Stiker Slip (SS)  4-6  600-   \n",
                            "2  RSN8459_PARK2004  32380.0  1 Stiker Slip (SS)  4-6  600-   \n",
                            "3   RSN2148_BEARCTY   8200.0  1 Stiker Slip (SS)  4-6  600-   \n",
                            "4   RSN8426_BEARCTY  14465.0  1 Stiker Slip (SS)  4-6  600-   \n",
                            "\n",
                            "                                                Time  \\\n",
                            "0  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
                            "1  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
                            "2  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
                            "3  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
                            "4  [0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07...   \n",
                            "\n",
                            "                                                AccV  \\\n",
                            "0  [3.3443977e-08, 3.3695554e-08, 3.3943394e-08, ...   \n",
                            "1  [8.5424888e-09, 8.8524636e-09, 9.1842936e-09, ...   \n",
                            "2  [5.855578e-08, 5.9356899e-08, 6.0156329e-08, 6...   \n",
                            "3  [-2.276836e-05, -2.118971e-05, -2.810751e-05, ...   \n",
                            "4  [3.079444e-09, 3.07869528e-09, 3.07794452e-09,...   \n",
                            "\n",
                            "                                               AccH2  \\\n",
                            "0  [-5.5774385e-08, -5.6530193e-08, -5.7289814e-0...   \n",
                            "1  [-2.2300064e-09, -2.3446809e-09, -2.4440089e-0...   \n",
                            "2  [2.7169869e-08, 2.7004326e-08, 2.6835684e-08, ...   \n",
                            "3  [7.43878e-06, 5.521958e-06, -2.429367e-06, -6....   \n",
                            "4  [4.3128452e-10, 4.27025392e-10, 4.22775078e-10...   \n",
                            "\n",
                            "                                               AccH1  \n",
                            "0  [-1.931981e-08, -1.9326151e-08, -1.9334876e-08...  \n",
                            "1  [8.4741547e-10, 1.2447632e-09, 1.6283558e-09, ...  \n",
                            "2  [1.5000493e-08, 1.4939016e-08, 1.4878223e-08, ...  \n",
                            "3  [1.001939e-05, 9.63514e-06, 1.253978e-05, 1.00...  \n",
                            "4  [2.9098055e-09, 2.89089174e-09, 2.87200576e-09...  "
                        ]
                    },
                    "execution_count": 32,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 11: Conversión a DataFrame y limpieza\n",
                "# ----------------------------------------------------------------------------------\n",
                "df = pd.DataFrame(grupos_normalizados)\n",
                "df = df.drop(columns=['DT'])  # eliminar DT redundante\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "005cccf6",
            "metadata": {},
            "source": [
                "## Bloque 12 – Guardar JSON"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "5167a8e2",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ----------------------------------------------------------------------------------\n",
                "# BLOQUE 12: Guardar DataFrame a JSON\n",
                "# ----------------------------------------------------------------------------------\n",
                "df.to_json('data/interim/datosML.json', orient='records', lines=True)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "env",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
