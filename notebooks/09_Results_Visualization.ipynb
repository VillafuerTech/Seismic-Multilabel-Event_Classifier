{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0f56da",
   "metadata": {},
   "source": [
    "# Conclusiones: Comparación de los tres modelos multietiqueta\n",
    "\n",
    "## 1. Rendimiento numérico (F1-micro)\n",
    "\n",
    "| Modelo                 | F1-micro (media ± std) |\n",
    "|------------------------|-----------------------:|\n",
    "| **SVM (RBF, OvR)**     | 0.5387 ± 0.0095        |\n",
    "| **Random Forest**      | 0.6084 ± 0.0110        |\n",
    "| **Red neuronal densa** | 0.5966 ± 0.0118        |\n",
    "\n",
    "> **Nota:** Se reporta solo **F1-micro** porque el dataset está algo desbalanceado y F1-macro/Hamming loss pueden no reflejar bien la calidad global.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Definición de las métricas  \n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "  F1_{\\text{micro}} &= \n",
    "    \\frac{2 \\sum_{l} \\text{TP}_l}\n",
    "         {2 \\sum_{l} \\text{TP}_l + \\sum_{l} \\text{FP}_l + \\sum_{l} \\text{FN}_l}\n",
    "  \\\\[6pt]\n",
    "  F1_{\\text{macro}} &= \n",
    "    \\frac{1}{L}\\sum_{l=1}^{L} F1_l\n",
    "  \\\\[6pt]\n",
    "  \\text{HL} &= \n",
    "    \\frac{1}{N\\,L}\\sum_{i=1}^{N}\\sum_{l=1}^{L}\n",
    "      \\mathbf{1}\\!\\left[y_{il}\\neq\\hat y_{il}\\right]\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "- \\(L\\): número de etiquetas  \n",
    "- \\(N\\): número de muestras  \n",
    "- \\(\\text{TP},\\text{FP},\\text{FN}\\): verdaderos positivos, falsos positivos y falsos negativos\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Lectura de los resultados\n",
    "\n",
    "- **SVM con kernel RBF**  \n",
    "  - Obtiene un **F1-micro** promedio de **0.539**, el más bajo.  \n",
    "  - Su desempeño depende fuertemente de la elección de \\(\\gamma\\) y \\(C\\), y de la escala de las features.\n",
    "\n",
    "- **Random Forest**  \n",
    "  - Mejora notable hasta **0.608** (+0.069 respecto a SVM).  \n",
    "  - Captura bien interacciones no lineales y es menos sensible al escalado.\n",
    "\n",
    "- **Red neuronal densa**  \n",
    "  - F1-micro de **0.597**, muy próxima a Random Forest (−0.0118).  \n",
    "  - Su fortaleza está en modelar patrones complejos, aunque requiere mayor tuning y entrenamiento.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Conclusión general\n",
    "\n",
    "1. **Random Forest** es el ganador bajo este esquema, combinando robustez y buen rendimiento sin un tuning excesivo.  \n",
    "2. **Red neuronal** se sitúa en segundo lugar, con potencial para igualar o superar a RF si se dispone de más datos y se optimizan hiperparámetros.  \n",
    "3. **SVM** ofrece la menor efectividad aquí y exige cuidado en el ajuste de parámetros y preprocesamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c61a4e",
   "metadata": {},
   "source": [
    "# Referencias y Prompts — *Seismic-Multilabel-Event-Classifier*\n",
    "\n",
    "## 1. Prompts de Diseño e Implementación\n",
    "\n",
    "- **1.1 Configurar y cargar correctamente el modelo desde checkpoint:**  \n",
    "  > *Prompt:* \"Enséñame cómo cargar manualmente un checkpoint `.ckpt` en PyTorch Lightning, renombrando los `state_dict` si es necesario y utilizando los hiperparámetros almacenados.\"\n",
    "\n",
    "- **1.2 Corregir errores de importación en rutas relativas:**  \n",
    "  > *Prompt:* \"El módulo `src.seismic_model` no se importa correctamente, crea el archivo `seismic_model.py` en la carpeta correcta dentro del proyecto.\"\n",
    "\n",
    "- **1.3 Corrección de errores con Trainer en Lightning:**  \n",
    "  > *Prompt:* \"Corrige el error `model must be a LightningModule` que ocurre cuando trato de entrenar mi red neuronal en Lightning.\"\n",
    "\n",
    "## 2. Prompts de Corrección y Optimización\n",
    "\n",
    "- **2.1 Optimización de hiperparámetros para Random Forest y SVM:**  \n",
    "  > *Prompt:* \"Amplía el espacio de búsqueda para la optimización de hiperparámetros usando `RepeatedKFold` y `GridSearchCV` en Random Forest y SVM.\"\n",
    "\n",
    "- **2.2 Estandarización de entrada en cada fold:**  \n",
    "  > *Prompt:* \"Corrige la fuga de datos (`data leakage`) aplicando escalado (`StandardScaler`) *dentro* de cada partición de validación cruzada.\"\n",
    "\n",
    "- **2.3 Exportación de resultados de evaluación:**  \n",
    "  > *Prompt:* \"Guarda en CSV los resultados de cada fold de evaluación de los modelos para posterior análisis.\"\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Referencias Bibliográficas\n",
    "\n",
    "- [1] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, “Scikit-learn: Machine Learning in Python,” *Journal of Machine Learning Research*, vol. 12, pp. 2825–2830, 2011.\n",
    "\n",
    "- [2] Ó. E. Vásquez Pino, \"*Engineered Features* para la estimación de magnitud de eventos sísmicos,\" Memoria de Título, Departamento de Ingeniería Eléctrica, Facultad de Ciencias Físicas y Matemáticas, Universidad de Chile, 2023.\n",
    "\n",
    "- [3] Lightning AI, “Lightning AI: Idea to AI product, fast,” [https://lightning.ai](https://lightning.ai) (accedido el 28 de abril de 2025).\n",
    "\n",
    "- [4] Lightning AI. \"Lightning Documentation.\" [https://lightning.ai/docs/pytorch/stable/](https://lightning.ai/docs/pytorch/stable/)\n",
    "\n",
    "- [5] TorchMetrics. \"Multilabel Classification Metrics.\" [https://torchmetrics.readthedocs.io/en/stable/classification/multilabel.html](https://torchmetrics.readthedocs.io/en/stable/classification/multilabel.html)\n",
    "\n",
    "- [6] J. Demšar, \"Statistical Comparisons of Classifiers over Multiple Data Sets,\" *Journal of Machine Learning Research*, vol. 7, pp. 1–30, Jan. 2006.\n",
    "\n",
    "- [7] S. Raschka, \"Model Evaluation, Model Selection, and Algorithm Selection in Machine Learning,\" *arXiv preprint* arXiv:1811.12808, 2018.\n",
    "\n",
    "- [8] A. Géron, *Hands‑On Machine Learning with Scikit‑Learn, Keras & TensorFlow*, 3rd ed., O’Reilly Media, 2022.\n",
    "\n",
    "---\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
